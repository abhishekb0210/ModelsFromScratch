{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c937a4",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f3c35655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "35330832",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_sentences = '''I am an Angel. My name is Angelina. I look good on Sunday. I look ordinary on weekdays. \\\n",
    "I am into Programming. I am a good person'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "84ec5e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an Angel. My name is Angelina. I look good on Sunday. I look ordinary on weekdays. I am into Programming. I am a good person\n"
     ]
    }
   ],
   "source": [
    "print(inp_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50d24fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into individual docs on the basis of '.'\n",
    "docs = inp_sentences.split('.')\n",
    "docs = [doc.strip().lower() for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4154ad8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am an angel',\n",
       " 'my name is angelina',\n",
       " 'i look good on sunday',\n",
       " 'i look ordinary on weekdays',\n",
       " 'i am into programming',\n",
       " 'i am a good person']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the sentences(documents) for which we need to calculate tfidf, i.e., generate numeric features\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4b1d1",
   "metadata": {},
   "source": [
    "### Preparing vocabulary(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e93be82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'an',\n",
       " 'angel',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'angelina',\n",
       " 'look',\n",
       " 'good',\n",
       " 'on',\n",
       " 'sunday',\n",
       " 'ordinary',\n",
       " 'weekdays',\n",
       " 'into',\n",
       " 'programming',\n",
       " 'a',\n",
       " 'person']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unqiue words\n",
    "vocab = list()\n",
    "for i in inp_sentences.split():\n",
    "    i = i.replace('.', '').lower()\n",
    "    if i not in vocab and i not in [' ', '.']:\n",
    "        vocab.append(i)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "adaa5dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6*18\n"
     ]
    }
   ],
   "source": [
    "# for each sentence we will generate the word vectors, following the final output shape will be where each cell will consist of tfidf score:\n",
    "print(str(len(docs)) + \"*\" + str(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc3bda",
   "metadata": {},
   "source": [
    "### Calculating Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f69b85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdfGenerator:\n",
    "    def __init__(self, docs):\n",
    "        self.docs = docs\n",
    "        self.vocab = list()\n",
    "        self.tfidf = None\n",
    "        \n",
    "    def prepare_vocab(self):\n",
    "        for doc in self.docs:\n",
    "            for i in doc.split():\n",
    "                i = i.replace('.', '').lower()\n",
    "                if i not in self.vocab and i not in [' ', '.']:\n",
    "                    self.vocab.append(i)\n",
    "    \n",
    "    def get_tfidf(self):\n",
    "        # generate vocab of unique words\n",
    "        self.prepare_vocab()\n",
    "        \n",
    "        # Term-frequency = (# of times in current doc)/(# of terms in the current doc)\n",
    "        tf = np.zeros((len(self.docs), len(self.vocab)))\n",
    "        for i in range(len(self.docs)):\n",
    "            doc_len = len(self.docs[i])\n",
    "            count_dict = Counter(self.docs[i].split())\n",
    "            for j in range(len(self.vocab)):\n",
    "                tf[i][j] = count_dict[self.vocab[j]]/doc_len\n",
    "        \n",
    "        # inverse document frequency = log(# of docs/ # of docs in which term appears)\n",
    "        total_docs = len(self.docs)\n",
    "        idf = np.zeros(len(self.vocab))\n",
    "\n",
    "        for j in range(len(self.vocab)):\n",
    "            word_count = 0\n",
    "            for i in range(len(self.docs)):\n",
    "                count_dict = Counter(self.docs[i].split())\n",
    "                if self.vocab[j] in count_dict:\n",
    "                    word_count += 1\n",
    "            idf[j] = np.log(total_docs/word_count)   \n",
    "        \n",
    "        \n",
    "        # calculating tfidf\n",
    "        self.tfidf = tf * idf\n",
    "        return self.tfidf\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3fd710e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TfIdf = TfIdfGenerator(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b3dc8bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01402474, 0.05331901, 0.13782765, 0.13782765, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.09430313,\n",
       "        0.09430313, 0.09430313, 0.09430313, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.00868198, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05231487, 0.05231487,\n",
       "        0.05231487, 0.08532188, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.00675265, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04068934, 0.        ,\n",
       "        0.04068934, 0.        , 0.06636146, 0.06636146, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.00868198, 0.03300701, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08532188,\n",
       "        0.08532188, 0.        , 0.        ],\n",
       "       [0.01012898, 0.03850818, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06103402,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09954219, 0.09954219]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfIdf.get_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "11fbf129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'an',\n",
       " 'angel',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'angelina',\n",
       " 'look',\n",
       " 'good',\n",
       " 'on',\n",
       " 'sunday',\n",
       " 'ordinary',\n",
       " 'weekdays',\n",
       " 'into',\n",
       " 'programming',\n",
       " 'a',\n",
       " 'person']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfIdf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3a3bed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.05263158,\n",
       "        0.05263158, 0.05263158, 0.05263158, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.04761905, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04761905, 0.04761905,\n",
       "        0.04761905, 0.04761905, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.03703704, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03703704, 0.        ,\n",
       "        0.03703704, 0.        , 0.03703704, 0.03703704, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.04761905, 0.04761905, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.04761905,\n",
       "        0.04761905, 0.        , 0.        ],\n",
       "       [0.05555556, 0.05555556, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05555556,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05555556, 0.05555556]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "45528cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18232156, 0.69314718, 1.79175947, 1.79175947, 1.79175947,\n",
       "       1.79175947, 1.79175947, 1.79175947, 1.09861229, 1.09861229,\n",
       "       1.09861229, 1.79175947, 1.79175947, 1.79175947, 1.79175947,\n",
       "       1.79175947, 1.79175947, 1.79175947])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e590de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
